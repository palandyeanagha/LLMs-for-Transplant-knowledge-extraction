{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e8PWqviZa42",
        "outputId": "5d04faf0-2949-49eb-c1da-0e0f3819bb4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "STEP 1: TEXT EXTRACTION + METADATA\n",
            "============================================================\n",
            "Total PDFs: 1764\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExtracting:   0%|          | 0/1764 [00:00<?, ?pdf/s]/usr/local/lib/python3.12/dist-packages/pypdfium2/_helpers/textpage.py:80: UserWarning: get_text_range() call with default params will be implicitly redirected to get_text_bounded()\n",
            "  warnings.warn(\"get_text_range() call with default params will be implicitly redirected to get_text_bounded()\")\n",
            "Extracting: 100%|██████████| 1764/1764 [02:34<00:00, 11.43pdf/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 1 COMPLETE\n",
            "============================================================\n",
            "Total PDFs: 1764\n",
            "Need OCR: 5\n",
            "Time: 2.6 minutes\n",
            "\n",
            "Files saved as: {doi}.txt\n",
            "Text folder: /content/drive/MyDrive/Capstone/extracted_text\n",
            "Metadata CSV: /content/drive/MyDrive/Capstone/pdf_metadata.csv\n",
            "\n",
            "============================================================\n",
            "CSV PREVIEW - ALL PDFs\n",
            "============================================================\n",
            "                                                                                               pdf_title                          doi  file_size_mb  text_length  is_scanned  needs_ocr extraction_method\n",
            "                                                                 (page number not for citation purposes)        10.1186/1471-2482-8-2          0.21        31149       False      False         pypdfium2\n",
            "                                           416 Hong Kong Med J Vol 19 No 5 # October 2013 # www.hkmj.org          10.12809/hkmj133793          0.96        34901       False      False         pypdfium2\n",
            "                                                                 Two types of fatigue in cancer patients         10.1038/bjc.2011.528          0.10         4664       False      False         pypdfium2\n",
            "                                            Effect of Exercise on NAFLD and Its Risk Factors: Comparison     10.14218/JCTH.2019.00012          0.14        37098       False      False         pypdfium2\n",
            "                                                           Ann Hepatobiliary Pancreat Surg 2020;24:44-51  10.14701/ahbps.2020.24.1.44          0.34        27348       False      False         pypdfium2\n",
            "https://doi.org/10.3350/cmh.2017.0077 Original Article Clinical and Molecular Hepatology 2018;24:319-330        10.3350/cmh.2017.0077          1.04        46592       False      False         pypdfium2\n",
            "                      Scientific Reports | (2020) 10:5654 | https://doi.org/10.1038/s41598-020-62387-z 1   10.1038/s41598-020-62387-z          1.20        44735       False      False         pypdfium2\n",
            "         The Journal of Clinical Investigation http://www.jci.org Volume 123 Number 10 October 2013 4121             10.1172/JCI67714          3.56        68680       False      False         pypdfium2\n",
            "                                                                                   Vol.:(0123456789) 1 3   10.1007/s10396-020-01012-y          3.04        74164       False      False         pypdfium2\n",
            "                                     Receptor in Patients with Acute Myeloid Leukemia Preceded by Severe 10.3324/haematol.2013.094482          0.18        28390       False      False         pypdfium2\n",
            "\n",
            "============================================================\n",
            "STATISTICS\n",
            "============================================================\n",
            "is_scanned = True: 5\n",
            "needs_ocr = True: 5\n",
            "\n",
            "Text length distribution:\n",
            "count    1.764000e+03\n",
            "mean     4.841643e+04\n",
            "std      5.021041e+04\n",
            "min      7.900000e+01\n",
            "25%      3.062050e+04\n",
            "50%      4.112950e+04\n",
            "75%      5.520525e+04\n",
            "max      1.030865e+06\n",
            "Name: text_length, dtype: float64\n",
            "\n",
            "============================================================\n",
            "SCANNED PDFs (needs_ocr=True): 5\n",
            "============================================================\n",
            "                                     pdf_title                           doi  text_length  is_scanned  needs_ocr\n",
            "           Kobe University Repository : Kernel  10.3109/09513590.2013.829444          396        True       True\n",
            "                                       Unknown    10.3350/kjhep.2008.14.1.89           79        True       True\n",
            "NOTE: Weights are from random effects analysis 10.1016/j.metabol.2017.11.003          340        True       True\n",
            "           Kobe University Repository : Kernel             10.1002/jmv.23293          418        True       True\n",
            "                                       Unknown  10.1097/MPG.0000000000001792           89        True       True\n",
            "\n",
            "Run STEP 2 to OCR these 5 PDFs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# STEP 1: TEXT EXTRACTION + METADATA CSV\n",
        "# Saves as {doi}.txt\n",
        "# CSV columns: pdf_title, doi, file_size_mb, text_length,\n",
        "#              is_scanned, needs_ocr, extraction_method\n",
        "# ============================================\n",
        "\n",
        "import pypdfium2 as pdfium\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "PDF_FOLDER = \"/content/drive/MyDrive/Capstone/papers\"\n",
        "TEXT_OUTPUT = \"/content/drive/MyDrive/Capstone/extracted_text\"\n",
        "METADATA_CSV = \"/content/drive/MyDrive/Capstone/pdf_metadata.csv\"\n",
        "\n",
        "Path(TEXT_OUTPUT).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "all_pdfs = list(Path(PDF_FOLDER).glob('**/*.pdf'))\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"STEP 1: TEXT EXTRACTION + METADATA\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Total PDFs: {len(all_pdfs)}\\n\")\n",
        "\n",
        "def extract_doi_from_filename(filename):\n",
        "    \"\"\"Extract DOI from filename like '10.1186_1471-2482-8-2.pdf'\"\"\"\n",
        "    name = filename.replace('.pdf', '')\n",
        "    doi = name.replace('_', '/')\n",
        "    return doi\n",
        "\n",
        "def extract_title_from_text(text):\n",
        "    \"\"\"Extract likely title from first part of text\"\"\"\n",
        "    lines = text.strip().split('\\n')\n",
        "    for line in lines[:10]:\n",
        "        line = line.strip()\n",
        "        if len(line) > 20 and len(line) < 200:\n",
        "            return line\n",
        "    return \"Unknown\"\n",
        "\n",
        "metadata_records = []\n",
        "start_time = time.time()\n",
        "\n",
        "for idx, pdf_path in enumerate(tqdm(all_pdfs, desc=\"Extracting\", unit=\"pdf\")):\n",
        "\n",
        "    doi = extract_doi_from_filename(pdf_path.name)\n",
        "    txt_file = Path(TEXT_OUTPUT) / f\"{doi.replace('/', '_')}.txt\"\n",
        "\n",
        "    record = {\n",
        "        'pdf_title': 'Unknown',\n",
        "        'doi': doi,\n",
        "        'file_size_mb': round(pdf_path.stat().st_size / (1024 * 1024), 2),\n",
        "        'text_length': 0,\n",
        "        'is_scanned': False,\n",
        "        'needs_ocr': False,\n",
        "        'extraction_method': 'none'\n",
        "    }\n",
        "\n",
        "    if txt_file.exists():\n",
        "        with open(txt_file, 'r', encoding='utf-8') as f:\n",
        "            text = f.read()\n",
        "\n",
        "        record['text_length'] = len(text.strip())\n",
        "        record['extraction_method'] = 'pypdfium2'\n",
        "        record['pdf_title'] = extract_title_from_text(text)\n",
        "\n",
        "        if record['text_length'] < 500:\n",
        "            record['is_scanned'] = True\n",
        "            record['needs_ocr'] = True\n",
        "\n",
        "        metadata_records.append(record)\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        pdf = pdfium.PdfDocument(pdf_path)\n",
        "        text = \"\"\n",
        "\n",
        "        for i in range(len(pdf)):\n",
        "            page = pdf[i]\n",
        "            textpage = page.get_textpage()\n",
        "            page_text = textpage.get_text_range()\n",
        "            if page_text:\n",
        "                text += page_text + \"\\n\\n\"\n",
        "\n",
        "        pdf.close()\n",
        "\n",
        "        with open(txt_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(text)\n",
        "\n",
        "        record['text_length'] = len(text.strip())\n",
        "        record['extraction_method'] = 'pypdfium2'\n",
        "        record['pdf_title'] = extract_title_from_text(text)\n",
        "\n",
        "        if record['text_length'] < 500:\n",
        "            record['is_scanned'] = True\n",
        "            record['needs_ocr'] = True\n",
        "\n",
        "    except Exception as e:\n",
        "        record['extraction_method'] = 'failed'\n",
        "        record['needs_ocr'] = True\n",
        "        record['is_scanned'] = True\n",
        "\n",
        "    metadata_records.append(record)\n",
        "\n",
        "metadata_df = pd.DataFrame(metadata_records)\n",
        "metadata_df.to_csv(METADATA_CSV, index=False)\n",
        "\n",
        "elapsed_time = time.time() - start_time\n",
        "needs_ocr_count = len(metadata_df[metadata_df['needs_ocr'] == True])\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"STEP 1 COMPLETE\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Total PDFs: {len(metadata_df)}\")\n",
        "print(f\"Need OCR: {needs_ocr_count}\")\n",
        "print(f\"Time: {elapsed_time/60:.1f} minutes\")\n",
        "print(f\"\\nFiles saved as: {{doi}}.txt\")\n",
        "print(f\"Text folder: {TEXT_OUTPUT}\")\n",
        "print(f\"Metadata CSV: {METADATA_CSV}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"CSV PREVIEW - ALL PDFs\")\n",
        "print(f\"{'='*60}\")\n",
        "print(metadata_df.head(10).to_string(index=False))\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"STATISTICS\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"is_scanned = True: {len(metadata_df[metadata_df['is_scanned'] == True])}\")\n",
        "print(f\"needs_ocr = True: {len(metadata_df[metadata_df['needs_ocr'] == True])}\")\n",
        "print(f\"\\nText length distribution:\")\n",
        "print(metadata_df['text_length'].describe())\n",
        "\n",
        "if needs_ocr_count > 0:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"SCANNED PDFs (needs_ocr=True): {needs_ocr_count}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    scanned_preview = metadata_df[metadata_df['needs_ocr'] == True][['pdf_title', 'doi', 'text_length', 'is_scanned', 'needs_ocr']]\n",
        "    print(scanned_preview.head(20).to_string(index=False))\n",
        "    print(f\"\\nRun STEP 2 to OCR these {needs_ocr_count} PDFs\")\n",
        "else:\n",
        "    print(\"\\nAll PDFs have sufficient text - no OCR needed\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# STEP 2: TESSERACT OCR FOR SCANNED PDFs\n",
        "# Replaces low-quality text files with OCR\n",
        "# Updates metadata CSV\n",
        "# ============================================\n",
        "\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "# Install OCR dependencies FIRST\n",
        "print(\"Installing OCR tools...\")\n",
        "subprocess.run([\"apt-get\", \"update\"], capture_output=True)\n",
        "subprocess.run([\"apt-get\", \"install\", \"-y\", \"tesseract-ocr\", \"poppler-utils\"],\n",
        "               capture_output=True)\n",
        "subprocess.run([\"pip\", \"install\", \"pytesseract\", \"pdf2image\", \"Pillow\"],\n",
        "               capture_output=True)\n",
        "\n",
        "print(\"OCR tools installed\\n\")\n",
        "\n",
        "# NOW import the modules\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import pdf2image\n",
        "\n",
        "# Paths\n",
        "PDF_FOLDER = \"/content/drive/MyDrive/Capstone/papers\"\n",
        "TEXT_OUTPUT = \"/content/drive/MyDrive/Capstone/extracted_text\"\n",
        "METADATA_CSV = \"/content/drive/MyDrive/Capstone/pdf_metadata.csv\"\n",
        "\n",
        "# Load metadata\n",
        "metadata_df = pd.read_csv(METADATA_CSV)\n",
        "needs_ocr_df = metadata_df[metadata_df['needs_ocr'] == True].copy()\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"STEP 2: TESSERACT OCR\")\n",
        "print(\"=\"*60)\n",
        "print(f\"PDFs to OCR: {len(needs_ocr_df)}\\n\")\n",
        "\n",
        "if len(needs_ocr_df) == 0:\n",
        "    print(\"No PDFs need OCR - all done\")\n",
        "else:\n",
        "    ocr_success = 0\n",
        "    ocr_failed = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, row in tqdm(needs_ocr_df.iterrows(), total=len(needs_ocr_df),\n",
        "                         desc=\"OCR\", unit=\"pdf\"):\n",
        "\n",
        "        doi = row['doi']\n",
        "        pdf_filename = doi.replace('/', '_') + '.pdf'\n",
        "        txt_file = Path(TEXT_OUTPUT) / f\"{doi.replace('/', '_')}.txt\"\n",
        "\n",
        "        # Find PDF\n",
        "        pdf_matches = list(Path(PDF_FOLDER).rglob(pdf_filename))\n",
        "        if not pdf_matches:\n",
        "            ocr_failed += 1\n",
        "            continue\n",
        "\n",
        "        pdf_path = pdf_matches[0]\n",
        "\n",
        "        try:\n",
        "            # Convert PDF to images\n",
        "            images = pdf2image.convert_from_path(str(pdf_path), dpi=200)\n",
        "\n",
        "            # OCR each page\n",
        "            ocr_text = \"\"\n",
        "            for i, image in enumerate(images):\n",
        "                page_text = pytesseract.image_to_string(image, lang='eng')\n",
        "                ocr_text += page_text + \"\\n\\n\"\n",
        "\n",
        "            # Replace text file\n",
        "            with open(txt_file, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(ocr_text)\n",
        "\n",
        "            # Update metadata\n",
        "            metadata_df.loc[idx, 'text_length'] = len(ocr_text.strip())\n",
        "            metadata_df.loc[idx, 'extraction_method'] = 'tesseract_ocr'\n",
        "\n",
        "            # Update title\n",
        "            lines = ocr_text.strip().split('\\n')\n",
        "            for line in lines[:10]:\n",
        "                line = line.strip()\n",
        "                if len(line) > 20 and len(line) < 200:\n",
        "                    metadata_df.loc[idx, 'pdf_title'] = line\n",
        "                    break\n",
        "\n",
        "            ocr_success += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            ocr_failed += 1\n",
        "            metadata_df.loc[idx, 'extraction_method'] = f'ocr_failed: {str(e)[:50]}'\n",
        "\n",
        "        if (idx + 1) % 5 == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            rate = (idx + 1) / elapsed\n",
        "            eta = (len(needs_ocr_df) - idx - 1) / rate if rate > 0 else 0\n",
        "            print(f\"\\nOCR: {idx + 1}/{len(needs_ocr_df)}\")\n",
        "            print(f\"Success: {ocr_success} | Failed: {ocr_failed}\")\n",
        "            print(f\"Elapsed: {elapsed/60:.1f} min | ETA: {eta/60:.1f} min\\n\")\n",
        "\n",
        "    # Save updated metadata\n",
        "    metadata_df.to_csv(METADATA_CSV, index=False)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"STEP 2 COMPLETE\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"OCR success: {ocr_success}\")\n",
        "    print(f\"OCR failed: {ocr_failed}\")\n",
        "    print(f\"Time: {elapsed_time/60:.1f} minutes\")\n",
        "\n",
        "# Final summary\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"FINAL SUMMARY\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "total_files = len(list(Path(TEXT_OUTPUT).glob('*.txt')))\n",
        "print(f\"Total text files: {total_files}\")\n",
        "print(f\"\\nExtraction methods:\")\n",
        "print(metadata_df['extraction_method'].value_counts().to_string())\n",
        "print(f\"\\nText files: {TEXT_OUTPUT}\")\n",
        "print(f\"Metadata: {METADATA_CSV}\")\n",
        "print(\"\\nAll PDFs processed and ready for analysis\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwcIbGRcZhGJ",
        "outputId": "44fa2bfb-f988-421d-dc31-fab8806c56bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing OCR tools...\n",
            "OCR tools installed\n",
            "\n",
            "============================================================\n",
            "STEP 2: TESSERACT OCR\n",
            "============================================================\n",
            "PDFs to OCR: 5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OCR:  80%|████████  | 4/5 [02:54<00:40, 40.71s/pdf]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "OCR: 1565/5\n",
            "Success: 4 | Failed: 0\n",
            "Elapsed: 2.9 min | ETA: -2.9 min\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OCR: 100%|██████████| 5/5 [02:55<00:00, 35.07s/pdf]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "STEP 2 COMPLETE\n",
            "============================================================\n",
            "OCR success: 5\n",
            "OCR failed: 0\n",
            "Time: 2.9 minutes\n",
            "\n",
            "============================================================\n",
            "FINAL SUMMARY\n",
            "============================================================\n",
            "Total text files: 1764\n",
            "\n",
            "Extraction methods:\n",
            "extraction_method\n",
            "pypdfium2        1759\n",
            "tesseract_ocr       5\n",
            "\n",
            "Text files: /content/drive/MyDrive/Capstone/extracted_text\n",
            "Metadata: /content/drive/MyDrive/Capstone/pdf_metadata.csv\n",
            "\n",
            "All PDFs processed and ready for analysis\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KhVpn9rEzj-A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}